{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implikationen unterschiedlicher Risikomanagement-Strategien auf das Wert-/Risikoprofil einer Gesamtposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Thomas Robert Holy 2019\n",
    "<br>\n",
    "Version 0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlegende Einstellungen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst müssen die notwendigen Pakete (auch Module) importiert werden, damit auf diese zugegriffen werden kann. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Programmbibliothek die Hilfsmittel für die Verwaltung von Daten und deren Analyse anbietet\n",
    "import scipy.stats as stats # SciPy ist ein Python-basiertes Ökosystem für Open-Source-Software für Mathematik, Naturwissenschaften und Ingenieurwissenschaften\n",
    "from scipy.stats import rankdata, norm  \n",
    "from scipy import array, linalg, dot\n",
    "import random # Dieses modul wird verwendet um Zufallszahlen zu ziehen\n",
    "import numpy as np # Programmbibliothek die eine einfache Handhabung von Vektoren, Matrizen oder generell großen mehrdimensionalen Arrays ermöglicht\n",
    "import math # Dieses Modul wird verwendet um Skalardaten zu berechnen, z. B. trigonometrische Berechnungen.\n",
    "import operator # Programmbibliothek, welche die Ausgaben übersichtlicher gestaltet\n",
    "import matplotlib.pyplot as plt # Programmbibliothek die es erlaubt mathematische Darstellungen aller Art anzufertigen\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime as dt # Das datetime-Modul stellt Klassen bereit, mit denen Datums- und Uhrzeitangaben auf einfache und komplexe Weise bearbeitet werden können\n",
    "import random # Dieses Modul implementiert Pseudozufallszahlengeneratoren für verschiedene Verteilungen.\n",
    "import riskmeasure_module as rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden Einstellungen definiert, die die Formatierung der Ausgaben betreffen.\n",
    "Hierfür wird das Modul `operator` genutzt.\n",
    "Außerdem wird die Größe der Grafiken modifiziert, welche später angezeigt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "SCREEN_WIDTH = 140 \n",
    "centered = operator.methodcaller('center', SCREEN_WIDTH) \n",
    "pd.set_option('display.width', 125) \n",
    "plt.rcParams[\"figure.figsize\"] = 15,12.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensätze einlesen und manipulieren:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden Datensätze eingelesen und manipuliert.\n",
    "Da Jupyter Notebook leider Eingaben nicht zeilenweise einlesen kann, müssen die Datensätze manuell definiert und anschließend zum Array \"dateinamen\" hinzufügt werden.\n",
    "Standardmäßig werden fünf Datensätze (example1, ..., example5) definiert und im Array \"dateinamen\" gespeichert.\n",
    "<br>\n",
    "Anschließend wird aus jedem eingelesen Datensatz der Aktienkurs zum jeweiligen Tag extrahiert werden. \n",
    "Dieser Schritt wird automatisiert, indem zunächst die leere Liste \"kurse\" anlegt wird und anschließend von jedem sich in der Liste \"dateinamen\" befindenden Eintrag die jeweiligen Spalten \"Date\" und \"Adj Close\" eingelesen werden.\n",
    "Dabei werden die verschiedenen im Datensatz vorhanden Spalten mit jedem Komma separiert und Punkte werden als Zeichen für die Dezimaltrennung interpretiert. Anschließend werden die so extrahierten Daten zum Array \"kurse\" hinzugefügt.\n",
    "<br>\n",
    "Danach wird das Modul `datetime` genutzt, um die Datumsspalte des jeweiligen Datensatzes bearbeitbar zu machen.\n",
    "Zudem wird dem Programm mitgeteilt, dass die Einträge der Spalte \"Adj Close\" numerisch sind und mit ihnen gerechnet werden kann. Kommt es dabei zu Fehlern werden die entsprechende Werte als NaN-Werte behandelt.\n",
    "<br><br>\n",
    "Hinweis: An dieser Stelle können alternativ \"richtige\" Datensätze eingelesen werden, indem z.B. \"example1\" in BAS.DE usw. umbenannt werden, sofern die entsprechenden Datensätze im Home-Verzeichnis hochgeladen wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "datensatz1 = 'example1'\n",
    "datensatz2 = 'example2'\n",
    "datensatz3 = 'example3'\n",
    "datensatz4 = 'example4'\n",
    "datensatz5 = 'example5'\n",
    "\"\"\"\n",
    "datensatz1 = 'BAS.DE'\n",
    "datensatz2 = 'FME.DE'\n",
    "datensatz3 = 'NSU.DE'\n",
    "datensatz4 = 'SIE.DE'\n",
    "datensatz5 = 'VOW3.DE'\n",
    "\n",
    "dateinamen = [datensatz1,datensatz2,datensatz3,datensatz4,datensatz5]\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################\n",
    "\n",
    "kurse = []\n",
    "for eintrag in dateinamen:\n",
    "    kurs = pd.read_csv(str(eintrag) + '.csv',\n",
    "                decimal='.',\n",
    "                usecols=['Date','Adj Close'])\n",
    "    kurse.append(kurs) \n",
    "\n",
    "for eintrag in kurse:\n",
    "    eintrag['Date'] = pd.to_datetime(eintrag['Date']) \n",
    "    eintrag['Adj Close'] = pd.to_numeric(eintrag['Adj Close'], errors='coerce') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden zwei verschiedene DataFrames erzeugt, wobei \"kurschart_0\" die Basis für das Sharpe-Portfolio und \"kurschart_1\" die Basis für die Naive Diversifikation darstellt.\n",
    "Beiden beinhalten die täglichen aus den eingelesenen Aktienkursen berechneten Renditen, wobei für \"kurschart_1\" direkt die Portfolio-Rendite mittels Naiver Diversifikation ermittelt wird.\n",
    "Beide DataFrames sind auf die Handelstage eines Jahres beschränkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurschart_0 = pd.DataFrame()\n",
    "kurschart_1 = pd.DataFrame()\n",
    "\n",
    "zaehler = 0\n",
    "for eintrag in kurse:\n",
    "    x = dateinamen[zaehler]\n",
    "    kurschart_0['Aktienkurs ' + str(x)] = eintrag['Adj Close']\n",
    "    kurschart_1['Aktienkurs ' + str(x)] = eintrag['Adj Close']    \n",
    "    zaehler += 1\n",
    "\n",
    "kurschart_0 = kurschart_0[:252]\n",
    "kurschart_0 = kurschart_0.pct_change()\n",
    "kurschart_1 = kurschart_1[:252]\n",
    "kurschart_1 = kurschart_1.pct_change()\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Naive Diversifikation \n",
    "\n",
    "kurschart_1['PF-Rendite'] = (kurschart_1.sum(axis = 1, skipna = True) / len(dateinamen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo-Simulation: Sharpe PF, efficient Frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of efficient frontier: https://medium.com/python-data/effient-frontier-in-python-34b0c3043314, https://medium.com/python-data/efficient-frontier-portfolio-optimization-with-python-part-2-2-2fe23413ad94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = 253\n",
    "\n",
    "# calculate daily and annual returns of the stocks\n",
    "returns_daily = kurschart_0\n",
    "returns_annual = returns_daily.mean() * trading_days\n",
    "\n",
    "# get daily and covariance of returns of the stock\n",
    "cov_daily = returns_daily.cov()\n",
    "cov_annual = cov_daily * trading_days\n",
    "\n",
    "port_returns = []\n",
    "port_volatility = []\n",
    "sharpe_ratio = []\n",
    "stock_weights = []\n",
    "\n",
    "# set the number of combinations for imaginary portfolios\n",
    "num_assets = len(dateinamen)\n",
    "num_portfolios = 10000\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# populate the empty lists with each portfolios returns,risk and weights\n",
    "\n",
    "for single_portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    returns = np.dot(weights, returns_annual)\n",
    "    volatility = np.sqrt(np.dot(weights.T, np.dot(cov_annual, weights)))\n",
    "    sharpe = returns / volatility\n",
    "    sharpe_ratio.append(sharpe)\n",
    "    port_returns.append(returns)\n",
    "    port_volatility.append(volatility)\n",
    "    stock_weights.append(weights)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# a dictionary for Returns and Risk values of each portfolio\n",
    "portfolio = {'Returns': port_returns,\n",
    "             'Volatility': port_volatility,\n",
    "             'Sharpe Ratio': sharpe_ratio}\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# extend original dictionary to accomodate each ticker and weight in the portfolio\n",
    "for counter, symbol in enumerate(dateinamen):\n",
    "    portfolio[symbol + ' Weight'] = [Weight[counter] for Weight in stock_weights]\n",
    "\n",
    "# make a nice dataframe of the extended dictionary\n",
    "df = pd.DataFrame(portfolio)\n",
    "\n",
    "# get better labels for desired arrangement of columns\n",
    "column_order = ['Returns', 'Volatility', 'Sharpe Ratio'] + [stock + ' Weight' for stock in dateinamen]\n",
    "\n",
    "# reorder dataframe columns\n",
    "df = df[column_order]\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# find min Volatility & max sharpe values in the dataframe (df)\n",
    "min_volatility = df['Volatility'].min()\n",
    "max_sharpe = df['Sharpe Ratio'].max()\n",
    "\n",
    "# use the min, max values to locate and create the two special portfolios\n",
    "sharpe_portfolio = df.loc[df['Sharpe Ratio'] == max_sharpe]\n",
    "min_variance_port = df.loc[df['Volatility'] == min_volatility]\n",
    "\n",
    "# plot frontier, max sharpe & min Volatility values with a scatterplot\n",
    "plt.style.use('seaborn-dark')\n",
    "df.plot.scatter(x='Volatility', y='Returns', c='Sharpe Ratio',\n",
    "                cmap='RdYlGn', edgecolors='black', figsize=(10, 8), grid=True)\n",
    "plt.scatter(x=sharpe_portfolio['Volatility'], y=sharpe_portfolio['Returns'], c='red', marker='D', s=200)\n",
    "plt.scatter(x=min_variance_port['Volatility'], y=min_variance_port['Returns'], c='blue', marker='D', s=200 )\n",
    "plt.xlabel('Volatility (Std. Deviation)')\n",
    "plt.ylabel('Expected Returns')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.show()\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# print the details of the 2 special portfolios\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('Minimum-Varianz-Portfolio: \\n' + str(min_variance_port.T))\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('Optimales Sharpe-Portfolio: \\n' + str(sharpe_portfolio.T))\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimales Sharpe-Portfolio und Datenbereinigung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Schritt werden die durch die Monte-Carlo-Simulation ermittelten optimalen Gewichte des Sharpe-Portfolios auf den DataFrame \"kurschart_0\" angewendet, sodass im Anschluss die Portfolio-Rendite errechnet werden kann.\n",
    "Danach werden die Portfolio-Renditen in einer Liste gespeichert und bereinigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# Optimales Sharpe-Portfolio\n",
    "\n",
    "sharpe_portfolio = sharpe_portfolio.values.tolist()\n",
    "sharpe_portfolio = sharpe_portfolio[0][3::]\n",
    "\n",
    "kurschart_0 = kurschart_0.multiply(sharpe_portfolio, axis = 1)\n",
    "kurschart_0['PF-Rendite'] = kurschart_0.sum(axis = 1, skipna = True)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Datenbereinigung\n",
    "\n",
    "sharpe_values_PF = kurschart_0['PF-Rendite'].values.tolist()\n",
    "sharpe_values_PF = np.array(sharpe_values_PF)\n",
    "sharpe_values_PF = sharpe_values_PF[np.logical_not(np.isnan(sharpe_values_PF))]\n",
    "sharpe_values_PF = sharpe_values_PF[sharpe_values_PF != 0.0]\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "naiv_values_PF = kurschart_1['PF-Rendite'].values.tolist()\n",
    "naiv_values_PF = np.array(naiv_values_PF)\n",
    "naiv_values_PF = naiv_values_PF[np.logical_not(np.isnan(naiv_values_PF))]\n",
    "naiv_values_PF = naiv_values_PF[naiv_values_PF != 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung des Sharpe-Portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen Definieren und Verteilungsfunktionen plotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt werden zunächst Mittelwert und Standardabweichung des Sharpe-Portfolios berechnet und ausgegeben. \n",
    "Anschließend werden Funktionen definiert, welche das Plotten der Verteilungsfunktionen für die historische Simulation und die Varianz-Kovarianz-Methode und die Ermittlung der Risikomaße auf Basis des jeweiligen Simulationsverfahrens vereinfachen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##############################################################################################################################################')\n",
    "print('|' + centered('Optimales PF nach Sharpe') + '| ')\n",
    "print('##############################################################################################################################################')\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "mu_sharpe_PF = np.mean(sharpe_values_PF)\n",
    "std_sharpe_PF = np.std(sharpe_values_PF)\n",
    "\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Die Porfolio-Rendite hat einen Erwartunswert i.H.v. ' + str(mu_sharpe_PF) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Das Porfolio hat eine Standardabweichung i.H.v. ' + str(std_sharpe_PF) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "mini_values_PF = min(min(naiv_values_PF), min(sharpe_values_PF))\n",
    "maxi_values_PF = max(max(naiv_values_PF), max(sharpe_values_PF)) \n",
    "\n",
    "bins = len(naiv_values_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Historische Simulation - Plot\n",
    "\n",
    "def hist_sim(values, bins):\n",
    "    H, X1 = np.histogram(values, bins, density=True)\n",
    "    dx = X1[1] - X1[0]\n",
    "    F1 = np.cumsum(H) * dx \n",
    "    plt.plot(X1[1:], F1) \n",
    "    \n",
    "hist_sim(sharpe_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Varianz-Kovarianz-Methode - Plot\n",
    "\n",
    "def var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu, std):\n",
    "    global var_covar_results\n",
    "    \n",
    "    array = np.array(np.arange(0.0001, 1, 0.0001))\n",
    "    var_covar_results = stats.norm.ppf(array, mu, std)\n",
    "\n",
    "    var_covar_range = np.linspace(mini_values_PF, maxi_values_PF, bins)\n",
    "    plt.plot(var_covar_range, stats.norm.cdf(var_covar_range, mu, std))\n",
    "    \n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_sharpe_PF, std_sharpe_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "def easy_plot():\n",
    "    plt.xlabel('Rendite') \n",
    "    plt.ylabel('Wahrscheinlichkeit') \n",
    "    blue_patch = mpatches.Patch(color='blue', label='Historische Simulation') \n",
    "    orange_patch = mpatches.Patch(color='orange', label='Varianz-Kovarianzmethode') \n",
    "    plt.legend(handles=[orange_patch, blue_patch]) \n",
    "    plt.title('Verteilungsfunktion: Historische Simulation versus Varianz-Kovarianz-Methode')\n",
    "    plt.grid() \n",
    "    plt.axhline(0, color='black') \n",
    "    plt.axvline(0, color='black') \n",
    "    plt.show() \n",
    "easy_plot() \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Historische Simulation\n",
    "\n",
    "RM_list = []\n",
    "def risk(values, alpha, gamma):\n",
    "    global RM_list\n",
    "    \n",
    "    alle_RM =  rm.risk_measure()\n",
    "    alle_RM.get_all(values, alpha, gamma)\n",
    "    VaR, CVaR, Power_Risk, Power_EW = alle_RM.all\n",
    "    \n",
    "    RM_list.append([VaR, CVaR, Power_Risk, Power_EW])\n",
    "\n",
    "    print('|' + centered('Der VaR beträgt: ' + str(VaR) + '.') + '| ')\n",
    "    print('|' + centered('Der CVaR beträgt: ' + str(CVaR) + '.') + '| ')\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Power-Spektrales Risikomaß:') + '| ')\n",
    "    print('|' + centered('Der Erwartungswert beträgt: ' + str(Power_EW) + '.') + '| ')\n",
    "    print('|' + centered('Das Risiko beträgt: ' + str(Power_Risk) + '.') + '| ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risikomaße schätzen - Parameterfestlegung und Aufruf der Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.5\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################\n",
    "\n",
    "print('##############################################################################################################################################')\n",
    "print('|' + centered('Sharpe: Risikomessung - Historische Simulation') + '| ')\n",
    "print('##############################################################################################################################################')\n",
    "\n",
    "risk(sharpe_values_PF, alpha, gamma)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Varianz-Kovarianz-Methode\n",
    "\n",
    "print('##############################################################################################################################################')\n",
    "print('|' + centered('Sharpe: Risikomessung - Varianz-Kovarianz-Methode') + '| ')\n",
    "print('##############################################################################################################################################')\n",
    "\n",
    "risk(var_covar_results, alpha, gamma)\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung des naiv diversifizierten Portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Funktionen zum Plotten der Verteilungsfunktionen und zur Risikomessung im vorherigen Schritt bereits definiert wurden, müssen diese hier nur noch mit den entsprechenden Daten der naiven Diversifikation aufgerufen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##############################################################################################################################################')\n",
    "print('|' + centered('Naive Diversifikation') + '| ')\n",
    "print('##############################################################################################################################################')\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "mu_naiv_PF = np.mean(naiv_values_PF)\n",
    "std_naiv_PF = np.std(naiv_values_PF)\n",
    "\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Die Porfolio-Rendite hat einen Erwartunswert i.H.v. ' + str(mu_naiv_PF) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Das Porfolio hat somit eine Standardabweichung i.H.v. ' + str(std_naiv_PF) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Historische Simulation - Plot\n",
    "\n",
    "hist_sim(naiv_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Varianz-Kovarianz-Methode - Plot\n",
    "\n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_naiv_PF, std_naiv_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "easy_plot() \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Historische Simulation\n",
    "\n",
    "print('##############################################################################################################################################')\n",
    "print('|' + centered('Sharpe: Risikomessung - Historische Simulation') + '| ')\n",
    "print('##############################################################################################################################################')\n",
    "\n",
    "risk(naiv_values_PF, alpha, gamma)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Varianz-Kovarianz-Methode\n",
    "\n",
    "print('##############################################################################################################################################')\n",
    "print('|' + centered('Sharpe: Risikomessung - Varianz-Kovarianz-Methode') + '| ')\n",
    "print('##############################################################################################################################################')\n",
    "\n",
    "risk(naiv_values_PF, alpha, gamma)\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gegenüberstellung der Verteilungsfunktionen und Risikomaße"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Verteilungsfunktionen und die berechneten Risikomaße besser vergleichen zu können, werden diese hier noch einmal zusammengetragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "#  Sharpe-Portfolio: Historische Simulation - Plot (Blau)\n",
    "\n",
    "hist_sim(sharpe_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Sharpe-Portfolio: Varianz-Kovarianz-Methode - Plot (Orange)\n",
    "\n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_sharpe_PF, std_sharpe_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Naive Diversifikation: Historische Simulation - Plot (Grün)\n",
    "\n",
    "hist_sim(naiv_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Naive Diversifikation: Varianz-Kovarianz-Methode - Plot (Rot)\n",
    "\n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_naiv_PF, std_naiv_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "plt.xlabel('Rendite') \n",
    "plt.ylabel('Wahrscheinlichkeit') \n",
    "blue_patch = mpatches.Patch(color='blue', label='Sharpe - Historische Simulation') \n",
    "orange_patch = mpatches.Patch(color='orange', label='Sharpe - Varianz-Kovarianzmethode') \n",
    "green_patch = mpatches.Patch(color='green', label='Naiv - Historische Simulation') \n",
    "red_patch = mpatches.Patch(color='red', label='Naiv - Varianz-Kovarianzmethode')     \n",
    "plt.legend(handles=[orange_patch, blue_patch, green_patch, red_patch]) \n",
    "plt.title('Verteilungsfunktion: Sharpe/Naiv - Historische Simulation versus Varianz-Kovarianz-Methode')\n",
    "plt.grid() \n",
    "plt.axhline(0, color='black') \n",
    "plt.axvline(0, color='black') \n",
    "plt.show() \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# DataFrame Risikomessung: Übersicht\n",
    "\n",
    "RM_DataFrame = pd.DataFrame()\n",
    "RM_DataFrame['Index'] = ['VaR', 'CVaR', 'P-SRM (Risk)', 'P-SRM (EW)']\n",
    "RM_DataFrame['Sharpe + Historisch'] = RM_list[0]\n",
    "RM_DataFrame['Naiv + Historisch'] = RM_list[2]\n",
    "RM_DataFrame['Sharpe + VarKoVar'] = RM_list[1]\n",
    "RM_DataFrame['Naiv + VarKoVar'] = RM_list[3]\n",
    "RM_DataFrame = RM_DataFrame.set_index('Index')\n",
    "\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('Sharpe Portfolio versus Naive Diversifikation: Risikomessung') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print(RM_DataFrame)\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
