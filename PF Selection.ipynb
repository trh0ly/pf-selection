{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implikationen unterschiedlicher Risikomanagement-Strategien auf das Wert-/Risikoprofil einer Gesamtposition\n",
    "© Thomas Robert Holy 2019\n",
    "<br>\n",
    "Version 0.3.6\n",
    "<br><br>\n",
    "Visit me on GitHub: https://github.com/trh0ly\n",
    "## Grundlegende Einstellungen:\n",
    "Zunächst müssen die notwendigen Pakete (auch Module) importiert werden, damit auf diese zugegriffen werden kann. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Programmbibliothek die Hilfsmittel für die Verwaltung von Daten und deren Analyse anbietet\n",
    "import scipy.stats as stats # SciPy ist ein Python-basiertes Ökosystem für Open-Source-Software für Mathematik, Naturwissenschaften und Ingenieurwissenschaften\n",
    "from scipy.stats import rankdata, norm  \n",
    "from scipy import array, linalg, dot\n",
    "import random # Dieses modul wird verwendet um Zufallszahlen zu ziehen\n",
    "import numpy as np # Programmbibliothek die eine einfache Handhabung von Vektoren, Matrizen oder generell großen mehrdimensionalen Arrays ermöglicht\n",
    "import math # Dieses Modul wird verwendet um Skalardaten zu berechnen, z. B. trigonometrische Berechnungen.\n",
    "import operator # Programmbibliothek, welche die Ausgaben übersichtlicher gestaltet\n",
    "import matplotlib.pyplot as plt # Programmbibliothek die es erlaubt mathematische Darstellungen aller Art anzufertigen\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime as dt # Das datetime-Modul stellt Klassen bereit, mit denen Datums- und Uhrzeitangaben auf einfache und komplexe Weise bearbeitet werden können\n",
    "import random # Dieses Modul implementiert Pseudozufallszahlengeneratoren für verschiedene Verteilungen.\n",
    "import riskmeasure_module as rm # Dieses \"Modul\" vereinfacht die Berechnung der Risikomaße"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden Einstellungen definiert, die die Formatierung der Ausgaben betreffen.\n",
    "Hierfür wird das Modul `operator` genutzt.\n",
    "Außerdem wird die Größe der Grafiken modifiziert, welche später angezeigt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "SCREEN_WIDTH = 90\n",
    "centered = operator.methodcaller('center', SCREEN_WIDTH) \n",
    "pd.set_option('display.width', 125) \n",
    "plt.rcParams[\"figure.figsize\"] = 15,12.5 \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensätze einlesen und manipulieren:\n",
    "Nun werden Datensätze eingelesen und manipuliert.\n",
    "Da Jupyter Notebook leider Eingaben nicht zeilenweise einlesen kann, werden die Datensätze manuell definiert und anschließend zum Array \"dateinamen\" hinzufügt.\n",
    "Standardmäßig werden fünf Datensätze (example1, ..., example5) definiert und im Array \"dateinamen\" gespeichert.\n",
    "<br>\n",
    "Anschließend wird aus jedem eingelesen Datensatz der Aktienkurs zum jeweiligen Tag extrahiert werden. \n",
    "Dieser Schritt wird automatisiert, indem zunächst die leere Liste \"kurse\" anlegt wird und anschließend von jedem sich in der Liste \"dateinamen\" befindenden Eintrag die jeweiligen Spalten \"Date\" und \"Adj Close\" eingelesen werden.\n",
    "Dabei werden die verschiedenen im Datensatz vorhanden Spalten mit jedem Komma separiert und Punkte werden als Zeichen für die Dezimaltrennung interpretiert. Anschließend werden die so extrahierten Daten zum Array \"kurse\" hinzugefügt.\n",
    "<br>\n",
    "Danach wird das Modul `datetime` genutzt, um die Datumsspalte des jeweiligen Datensatzes bearbeitbar zu machen.\n",
    "Zudem wird dem Programm mitgeteilt, dass die Einträge der Spalte \"Adj Close\" numerisch sind und mit ihnen gerechnet werden kann. Kommt es dabei zu Fehlern werden die entsprechende Werte als NaN-Werte behandelt.\n",
    "<br><br>\n",
    "Hinweis: An dieser Stelle können alternativ \"richtige\" Datensätze eingelesen werden, indem z.B. \"example1\" in BAS.DE usw. umbenannt werden, sofern die entsprechenden Datensätze im Home-Verzeichnis hochgeladen wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "trading_days = 253\n",
    "\n",
    "datensatz1 = 'example1'\n",
    "datensatz2 = 'example2'\n",
    "datensatz3 = 'example3'\n",
    "datensatz4 = 'example4'\n",
    "datensatz5 = 'example5'\n",
    "\n",
    "dateinamen = [datensatz1,datensatz2,datensatz3,datensatz4,datensatz5]\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################\n",
    "\n",
    "kurse = []\n",
    "for eintrag in dateinamen:\n",
    "    kurs = pd.read_csv(str(eintrag) + '.csv',\n",
    "                decimal='.',\n",
    "                usecols=['Date','Adj Close'])\n",
    "    kurse.append(kurs) \n",
    "\n",
    "for eintrag in kurse:\n",
    "    eintrag['Date'] = pd.to_datetime(eintrag['Date']) \n",
    "    eintrag['Adj Close'] = pd.to_numeric(eintrag['Adj Close'], errors='coerce') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden zwei verschiedene DataFrames erzeugt, wobei \"kurschart_0\" die Basis für das Sharpe-Portfolio und \"kurschart_1\" die Basis für die Naive Diversifikation darstellt.\n",
    "Beide beinhalten die täglichen aus den eingelesenen Aktienkursen berechneten Renditen, wobei für \"kurschart_1\" direkt die Portfolio-Rendite mittels Naiver Diversifikation ermittelt wird.\n",
    "Beide DataFrames sind auf die Handelstage eines Jahres beschränkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurschart_0 = pd.DataFrame()\n",
    "kurschart_1 = pd.DataFrame()\n",
    "\n",
    "zaehler = 0\n",
    "for eintrag in kurse:\n",
    "    x = dateinamen[zaehler]\n",
    "    kurschart_0['Aktienkurs ' + str(x)] = eintrag['Adj Close']\n",
    "    kurschart_1['Aktienkurs ' + str(x)] = eintrag['Adj Close']    \n",
    "    zaehler += 1\n",
    "\n",
    "kurschart_0 = kurschart_0[:(trading_days - 1)]\n",
    "kurschart_0 = kurschart_0.pct_change()\n",
    "kurschart_1 = kurschart_1[:(trading_days - 1)]\n",
    "kurschart_1 = kurschart_1.pct_change()\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Naive Diversifikation \n",
    "\n",
    "kurschart_1['PF-Rendite'] = (kurschart_1.sum(axis = 1, skipna = True) / len(dateinamen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bestimmung des optimalen Sharpe-Portfolios mittels Monte-Carlo-Simulation\n",
    "In diesem Abschnitt werden zunächst die jährlichen Renditen und Kovarianzen der einzelnen Assets bestimmt.\n",
    "Anschließend wird auf Basis dieser Informationen eine Monte-Carlo-Siumulation durchgeführt durch welche das optimale Sharpe-Portfolio bestimmt wird.\n",
    "Hierfür werden n Zufallszahlen gezogen (n = Anzahl der Assets im Portfolio), welche anschließend so nomiert werden, dass sie in Summe Eins ergeben aber die Relationen untereinander erhalten bleiben.\n",
    "Im Anschluss wird die jeweilige jährliche Renditen der Asserts mit dem jeweiligen zuvor ermittelten Gewicht multipliziert, sodass sich eine Portfolio-Rendite ergibt.\n",
    "Gleichermaßen wird die dazugehörige Volatilität bestimmt, sodass daraufhin der Sharpe-Ratio ermittelt werden kann.\n",
    "Die so berechneten Größen werden jeweils in einer Liste gespeichert und in den DataFrame \"PF_DataFrame\" überführt, aus welchem sowohl das optimale Sharpe- als auch das Minimum-Varianz-Portfolio bestimmt wird.\n",
    "Zum Schluss wird eine Grafik generiert, welche den effizienten Rand darstellt.\n",
    "<br><br>\n",
    "Hinweis: Dieser Programmteil entstand in Anlehngung an \"Efficient Frontier & Portfolio Optimization with Python\" von Bernard Brenyah (https://github.com/PyDataBlog/Python-for-Data-Science/blob/master/Tutorials/Efficient%20Frontier%20with%20Sharpe%20Ratio.py) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_annual = kurschart_0.mean() * trading_days\n",
    "cov_daily = kurschart_0.cov()\n",
    "cov_annual = cov_daily * math.sqrt(trading_days)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "PF_return_list = []\n",
    "PF_volatility_list = []\n",
    "sharpe_ratio_list = []\n",
    "asset_weights_list = []\n",
    "\n",
    "n = 25000\n",
    "num_of_assets = len(dateinamen)\n",
    "\n",
    "for i in range(0,n):\n",
    "    random_weights = np.random.random(num_of_assets)\n",
    "    PF_weights = random_weights / np.sum(random_weights)\n",
    "    \n",
    "    PF_returns = np.dot(PF_weights, returns_annual)\n",
    "    PF_volatility = np.sqrt(np.dot(PF_weights.T, np.dot(cov_annual, PF_weights)))\n",
    "    sharpe_ratio = PF_returns / PF_volatility\n",
    "\n",
    "    asset_weights_list.append(PF_weights)\n",
    "    PF_return_list.append(PF_returns)\n",
    "    PF_volatility_list.append(PF_volatility)\n",
    "    sharpe_ratio_list.append(sharpe_ratio)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "PF_DataFrame = pd.DataFrame({'PF_Return': PF_return_list, 'PF_Volatility': PF_volatility_list, 'PF_Sharpe_Ratio': sharpe_ratio_list})\n",
    "for counter, dateiname in enumerate(dateinamen):\n",
    "    PF_DataFrame[str(dateiname) + ' Weight'] = [weight[counter] for weight in asset_weights_list]\n",
    "\n",
    "min_volatility = PF_DataFrame['PF_Volatility'].min()\n",
    "max_sharpe_ratio = PF_DataFrame['PF_Sharpe_Ratio'].max()\n",
    "Sharpe_PF = PF_DataFrame.loc[PF_DataFrame['PF_Sharpe_Ratio'] == max_sharpe_ratio]\n",
    "Min_variance_PF = PF_DataFrame.loc[PF_DataFrame['PF_Volatility'] == min_volatility]\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "plt.scatter(PF_volatility_list, PF_return_list, c = sharpe_ratio_list, marker='o', cmap='coolwarm', edgecolors='black')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.scatter(x = Sharpe_PF['PF_Volatility'], y = Sharpe_PF['PF_Return'], color='red', marker='v', edgecolors='black', s=300)\n",
    "plt.scatter(x = Min_variance_PF['PF_Volatility'], y = Min_variance_PF['PF_Return'], color='blue', edgecolors='black', marker='v', s=300)\n",
    "plt.grid()\n",
    "plt.ylabel('Erwartete Rendite')\n",
    "plt.title('Effizienter Rand und optimale Portfolios')\n",
    "plt.xlabel('Volatilität (Standardabweichung)')\n",
    "plt.show()\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('Minimum-Varianz-Portfolio: \\n' + str(Min_variance_PF.T))\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('Optimales Sharpe-Portfolio: \\n' + str(Sharpe_PF.T))\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimales Sharpe-Portfolio und Datenbereinigung\n",
    "In diesem Schritt werden die durch die Monte-Carlo-Simulation ermittelten optimalen Gewichte des Sharpe-Portfolios auf den DataFrame \"kurschart_0\" angewendet, sodass im Anschluss die Portfolio-Rendite errechnet werden kann.\n",
    "Danach werden die Portfolio-Renditen in einer Liste gespeichert und bereinigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# Optimales Sharpe-Portfolio\n",
    "\n",
    "Sharpe_PF = Sharpe_PF.values.tolist()\n",
    "Sharpe_PF = Sharpe_PF[0][3::]\n",
    "\n",
    "kurschart_0 = kurschart_0.multiply(Sharpe_PF, axis = 1)\n",
    "kurschart_0['PF-Rendite'] = kurschart_0.sum(axis = 1, skipna = True)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Datenbereinigung\n",
    "\n",
    "sharpe_values_PF = kurschart_0['PF-Rendite'].values.tolist()\n",
    "sharpe_values_PF = np.array(sharpe_values_PF)\n",
    "sharpe_values_PF = sharpe_values_PF[np.logical_not(np.isnan(sharpe_values_PF))]\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "naiv_values_PF = kurschart_1['PF-Rendite'].values.tolist()\n",
    "naiv_values_PF = np.array(naiv_values_PF)\n",
    "naiv_values_PF = naiv_values_PF[np.logical_not(np.isnan(naiv_values_PF))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung des Sharpe-Portfolios\n",
    "### Funktionen Definieren und Verteilungsfunktionen plotten\n",
    "In diesem Abschnitt werden zunächst Mittelwert und Standardabweichung des Sharpe-Portfolios berechnet und ausgegeben. \n",
    "Anschließend werden Funktionen definiert, welche das Plotten der Verteilungsfunktionen für die historische Simulation und die Varianz-Kovarianz-Methode und die Ermittlung der Risikomaße auf Basis des jeweiligen Simulationsverfahrens vereinfachen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "print('|' + centered('Optimales PF nach Sharpe') + '| ')\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "mu_sharpe_PF = np.mean(sharpe_values_PF)\n",
    "std_sharpe_PF = np.std(sharpe_values_PF)\n",
    "\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('|' + centered('[INFO] Die Porfolio-Rendite hat einen Erwartunswert i.H.v. ' + str(mu_sharpe_PF) + '.') + '| ')\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('|' + centered('[INFO] Das Porfolio hat eine Standardabweichung i.H.v. ' + str(std_sharpe_PF) + '.') + '| ')\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "\n",
    "mini_values_PF = min(min(naiv_values_PF), min(sharpe_values_PF))\n",
    "maxi_values_PF = max(max(naiv_values_PF), max(sharpe_values_PF)) \n",
    "\n",
    "bins = len(naiv_values_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Historische Simulation - Plot\n",
    "\n",
    "def hist_sim(values, bins):\n",
    "    H, X1 = np.histogram(values, bins, density=True)\n",
    "    dx = X1[1] - X1[0]\n",
    "    F1 = np.cumsum(H) * dx \n",
    "    plt.plot(X1[1:], F1) \n",
    "    \n",
    "hist_sim(sharpe_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Varianz-Kovarianz-Methode - Plot\n",
    "\n",
    "def var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu, std):\n",
    "    global var_covar_results\n",
    "    \n",
    "    array = np.array(np.arange(0.0001, 1, 0.0001))\n",
    "    var_covar_results = stats.norm.ppf(array, mu, std)\n",
    "\n",
    "    var_covar_range = np.linspace(mini_values_PF, maxi_values_PF, bins)\n",
    "    plt.plot(var_covar_range, stats.norm.cdf(var_covar_range, mu, std))\n",
    "    \n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_sharpe_PF, std_sharpe_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "def easy_plot():\n",
    "    plt.xlabel('Rendite') \n",
    "    plt.ylabel('Wahrscheinlichkeit') \n",
    "    blue_patch = mpatches.Patch(color='blue', label='Historische Simulation') \n",
    "    orange_patch = mpatches.Patch(color='orange', label='Varianz-Kovarianzmethode') \n",
    "    plt.legend(handles=[orange_patch, blue_patch]) \n",
    "    plt.title('Verteilungsfunktion: Historische Simulation versus Varianz-Kovarianz-Methode')\n",
    "    plt.grid() \n",
    "    plt.axhline(0, color='black') \n",
    "    plt.axvline(0, color='black') \n",
    "    plt.show() \n",
    "easy_plot() \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Historische Simulation\n",
    "\n",
    "RM_list = []\n",
    "def risk(values, alpha, gamma):\n",
    "    global RM_list\n",
    "    \n",
    "    alle_RM =  rm.risk_measure()\n",
    "    alle_RM.get_all(values, alpha, gamma)\n",
    "    VaR, CVaR, Power_Risk, Power_EW = alle_RM.all\n",
    "    \n",
    "    RM_list.append([VaR, CVaR, Power_Risk, Power_EW])\n",
    "\n",
    "    print('|' + centered('Der VaR beträgt: ' + str(VaR) + '.') + '| ')\n",
    "    print('|' + centered('Der CVaR beträgt: ' + str(CVaR) + '.') + '| ')\n",
    "    print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "    print('|' + centered('Power-Spektrales Risikomaß:') + '| ')\n",
    "    print('|' + centered('Der Erwartungswert beträgt: ' + str(Power_EW) + '.') + '| ')\n",
    "    print('|' + centered('Das Risiko beträgt: ' + str(Power_Risk) + '.') + '| ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risikomaße schätzen - Parameterfestlegung und Aufruf der Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.5\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################\n",
    "\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "print('|' + centered('Sharpe: Risikomessung - Historische Simulation') + '| ')\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "risk(sharpe_values_PF, alpha, gamma)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Varianz-Kovarianz-Methode\n",
    "\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "print('|' + centered('Sharpe: Risikomessung - Varianz-Kovarianz-Methode') + '| ')\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "\n",
    "risk(var_covar_results, alpha, gamma)\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung des naiv diversifizierten Portfolios\n",
    "Da die Funktionen zum Plotten der Verteilungsfunktionen und zur Risikomessung im vorherigen Schritt bereits definiert wurden, müssen diese hier nur noch mit den entsprechenden Daten der naiven Diversifikation aufgerufen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "print('|' + centered('Naive Diversifikation') + '| ')\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "mu_naiv_PF = np.mean(naiv_values_PF)\n",
    "std_naiv_PF = np.std(naiv_values_PF)\n",
    "\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('|' + centered('[INFO] Die Porfolio-Rendite hat einen Erwartunswert i.H.v. ' + str(mu_naiv_PF) + '.') + '| ')\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('|' + centered('[INFO] Das Porfolio hat somit eine Standardabweichung i.H.v. ' + str(std_naiv_PF) + '.') + '| ')\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Historische Simulation - Plot\n",
    "\n",
    "hist_sim(naiv_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Varianz-Kovarianz-Methode - Plot\n",
    "\n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_naiv_PF, std_naiv_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "easy_plot() \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Historische Simulation\n",
    "\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "print('|' + centered('Sharpe: Risikomessung - Historische Simulation') + '| ')\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "\n",
    "risk(naiv_values_PF, alpha, gamma)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Risikomessung - Varianz-Kovarianz-Methode\n",
    "\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "print('|' + centered('Sharpe: Risikomessung - Varianz-Kovarianz-Methode') + '| ')\n",
    "print((SCREEN_WIDTH + 2) * '#')\n",
    "\n",
    "risk(var_covar_results, alpha, gamma)\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gegenüberstellung der Verteilungsfunktionen und Risikomaße\n",
    "Um die Verteilungsfunktionen und die berechneten Risikomaße besser vergleichen zu können, werden diese hier noch einmal zusammengetragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "#  Sharpe-Portfolio: Historische Simulation - Plot (Blau)\n",
    "\n",
    "hist_sim(sharpe_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Sharpe-Portfolio: Varianz-Kovarianz-Methode - Plot (Orange)\n",
    "\n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_sharpe_PF, std_sharpe_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Naive Diversifikation: Historische Simulation - Plot (Grün)\n",
    "\n",
    "hist_sim(naiv_values_PF, bins)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Naive Diversifikation: Varianz-Kovarianz-Methode - Plot (Rot)\n",
    "\n",
    "var_co_var_sim(mini_values_PF, maxi_values_PF, bins, mu_naiv_PF, std_naiv_PF)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "plt.xlabel('Rendite') \n",
    "plt.ylabel('Wahrscheinlichkeit') \n",
    "blue_patch = mpatches.Patch(color='blue', label='Sharpe - Historische Simulation') \n",
    "orange_patch = mpatches.Patch(color='orange', label='Sharpe - Varianz-Kovarianzmethode') \n",
    "green_patch = mpatches.Patch(color='green', label='Naiv - Historische Simulation') \n",
    "red_patch = mpatches.Patch(color='red', label='Naiv - Varianz-Kovarianzmethode')     \n",
    "plt.legend(handles=[orange_patch, blue_patch, green_patch, red_patch]) \n",
    "plt.title('Verteilungsfunktion: Sharpe/Naiv - Historische Simulation versus Varianz-Kovarianz-Methode')\n",
    "plt.grid() \n",
    "plt.axhline(0, color='black') \n",
    "plt.axvline(0, color='black') \n",
    "plt.show() \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# DataFrame Risikomessung: Übersicht\n",
    "\n",
    "RM_DataFrame = pd.DataFrame()\n",
    "RM_DataFrame['Index'] = ['VaR', 'CVaR', 'P-SRM (Risk)', 'P-SRM (EW)']\n",
    "RM_DataFrame['Sharpe + Historisch'] = RM_list[0]\n",
    "RM_DataFrame['Naiv + Historisch'] = RM_list[2]\n",
    "RM_DataFrame['Sharpe + VarKoVar'] = RM_list[1]\n",
    "RM_DataFrame['Naiv + VarKoVar'] = RM_list[3]\n",
    "RM_DataFrame = RM_DataFrame.set_index('Index')\n",
    "\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print('|' + centered('Sharpe Portfolio versus Naive Diversifikation: Risikomessung') + '| ')\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')\n",
    "print(RM_DataFrame)\n",
    "print('#' + SCREEN_WIDTH * '-' + '#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "** Hinweis zur Verwendung des modizifierten Quellcodes von Bernard Brenyah zur Bestimmung des Sharpe Portfolios mittels Monte-Carlo Simulation:\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 Bernard Brenyah\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
